{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ef19cc",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "Preprocessing of text data has long been a key enabler for natural language processing. As the focus was on \"pure\" text data, side information such as formatting was not considered relevant.\n",
    "\n",
    "With the advent of large language models and their application to essentially any form of text -- that means, including e.g., HTML markup code and Python programs -- preprocessing has lost a lot of its prior importance, as nowadays the expectation is that the large language model should be able to appropriately handle e.g., HTML tags; i.e., it should identify them and either suppress them (if asked to extract the text) or correctly place them when prompted to produce a correctly coded website.\n",
    "\n",
    "For this reason, we will treat preprocessing rather briefly and just highlight a few examples. We will work with spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ce654",
   "metadata": {},
   "source": [
    "## Prepratation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d91eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccc0f0-223a-4cbf-9c30-3f839c122fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if necessary, install spacy and language models via anaconda or similar\n",
    "# en_core_web_sm is called spacy-model-en_core_web_sm in Anaconda\n",
    "# Or, directly from the notebook, you can install it with the following command:\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9004ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a language model - here we choose a rather small one for English trained on data scapped from the web.\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8eeb6",
   "metadata": {},
   "source": [
    "`nlp` is a 'traditional' language model, i.e., it contains the components of the classical NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The CAS AIS provides a targeted education in software, machine learning (ML) and artificial intelligence (AI)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d42efc",
   "metadata": {},
   "source": [
    "We can directly run this text through the the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f76472",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fb4be",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1d372",
   "metadata": {},
   "source": [
    "We can now access the individual tokens of the text as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([str(token) for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2142fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([str(token) for token in nlp(text.lower())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9c6f0",
   "metadata": {},
   "source": [
    "Our default sentence is rather simple in this regard. We move on to a more complicated one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mary, donâ€™t slap the green witch\"\n",
    "doc = nlp(text.lower())\n",
    "print([str(token) for token in doc ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd129",
   "metadata": {},
   "source": [
    "Here we see that the part \"don't\" has been split into 'do' and \"n't\" (for 'not'), thus separating these two parts that have been concatenated together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03fa1c",
   "metadata": {},
   "source": [
    "## Lemmatization and Morphology\n",
    "spaCy returns many other informations about the tokens in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(u\"he was running late\")\n",
    "for token in doc:\n",
    "    print('{} -> {}: {}'.format(token, token.lemma_, token.morph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3baf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Andreas Streich was running late\")\n",
    "for token in doc:\n",
    "    print('{} -> {}: {}'.format(token, token.lemma_, token.morph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c85f2",
   "metadata": {},
   "source": [
    "## Sentence Parsing\n",
    "Next, we can identify the different parts of the sentence (PoS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Mary slapped the green witch.\")\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"he was running late.\")\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The CAS AIS provides a targeted education in software, machine learning (ML) \\\n",
    "and artificial intelligence (AI). It is offered by ETH Zurich\")\n",
    "\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a1796",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "Stop words are very common words that are considered to be uninformative and therefore often removed in classical NLP approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print('{} - {}'.format(token.text, token.is_stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d170eac",
   "metadata": {},
   "source": [
    "## Noun Chunks and Named Entities\n",
    "`spaCy` can also identify different noun chunks, i.e., base noun phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a214d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print ('{} - {}'.format(chunk, chunk.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911dcc92",
   "metadata": {},
   "source": [
    "Next we want to look at named entities, i.e. persons, organisation etc. These are often of particular interest (in the sense of information extraction - who is this text about?), and they need to be handled specially when processing the text: Their names can consist of several words, and there is typically no translation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = nlp(\"The CAS AIS provides a targeted education in software, machine learning (ML) \\\n",
    "and artificial intelligence (AI). It is offered by ETH Zurich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in mydoc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = nlp(\"My name is Andreas Streich. I wort at ETH Zurich. \\\n",
    "             Last year, I was travelling to the United States of America\")\n",
    "for ent in mydoc.ents:\n",
    "    print(ent.text, '-->', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc35ccb",
   "metadata": {},
   "source": [
    "## Dependency Parsing\n",
    "Futhermore, we can identify which part of the sentence is depending on which other (e.g., subject, object, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = nlp(\"The CAS AIS provides a targeted education in software, machine learning (ML) \\\n",
    "and artificial intelligence (AI). It is offered by ETH Zurich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in mydoc.noun_chunks:\n",
    "    print(chunk.text, \"-\", chunk.root.text, \"-\", chunk.root.dep_, \"-\", chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d407767",
   "metadata": {},
   "source": [
    "For a visual presentation, we can use the `display` component of `spaCy`.\n",
    "\n",
    "**A technical hint**: if you are running this as a jupyter notebook, calling `display.serve(...)` will keep the cell busy (you will see a `*` on the left side, and you cannot run any other cell). To stop the cell and be able to continue with other parts of the notebook, you can interrupt the cell (with the \"stop\" buttom in the top ribbon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8730cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"Andreas Streich was running late.\")\n",
    "displacy.serve(mydoc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = nlp(\"Andreas Streich was running late.\")\n",
    "displacy.serve(mydoc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7933f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
