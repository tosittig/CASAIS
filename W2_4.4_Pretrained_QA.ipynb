{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffea51be",
   "metadata": {},
   "source": [
    "# Question-Answering\n",
    "Question answering is becoming more and more popular, as people seem to prefer to get answer interactively rather than reading long documents, and information can be found more quickly. \n",
    "\n",
    "We will the SubjQA dataset, which contains over 10'000 customer reviews in English  in six domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2944902",
   "metadata": {},
   "source": [
    "**Note:** If you get a `NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.` when running the cell `print(subjqa[\"train\"][\"answers\"][1])`: uncomment the following two `!pip` commands, restart the kernel, and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72de8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U typing-extensions\n",
    "# !pip install fsspec==2023.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d2212",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e4d6b",
   "metadata": {},
   "source": [
    "The `subjqa` has reviews from different domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40b9e7",
   "metadata": {},
   "source": [
    "We will use the feedbacks on electronics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "subjqa = load_dataset(\"subjqa\", name=\"electronics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274261b",
   "metadata": {},
   "source": [
    "Let's first look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d22603",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjqa[\"train\"][\"answers\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73783d",
   "metadata": {},
   "source": [
    "We re-organize the data into a structure that is more easy to handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee69d6",
   "metadata": {},
   "source": [
    "And we want to get an overview over how many data points we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc0d9c",
   "metadata": {},
   "source": [
    "Here are some of the most relevant attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_cols = [\"title\", \"question\", \"answers.text\",\n",
    "           \"answers.answer_start\", \"context\"]\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[791, 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[1159, 'context']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a64f5",
   "metadata": {},
   "source": [
    "As mentioned in the slides, we see that some of the answers are grammatically not correct sentences, and some cannot be answered (such as \"how is the battery?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd8fd7",
   "metadata": {},
   "source": [
    "## Span Classification\n",
    "A popular approach is to define a task to find the start and end token of the context that is contains the answer.\n",
    "\n",
    "Many models for this are available on e.g., Huggingface Hub. We choose a small one by deepset, a German AI start-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb291502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.\"\"\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3297d47",
   "metadata": {},
   "source": [
    "As before, we can get the tokens that the tokenizer has generated - and with `tokenizer.decode`, we see how our question and context are represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e05c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc93f39",
   "metadata": {},
   "source": [
    "After tokenization, we can use the model to predict the start and end token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1409c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a83ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s_scores = start_logits.detach().numpy().flatten()\n",
    "e_scores = end_logits.detach().numpy().flatten()\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "token_ids = range(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2451707",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "colors = [\"C0\" if s != np.max(s_scores) else \"C1\" for s in s_scores]\n",
    "ax1.bar(x=token_ids, height=s_scores, color=colors)\n",
    "ax1.set_ylabel(\"Start Scores\")\n",
    "colors = [\"C0\" if s != np.max(e_scores) else \"C1\" for s in e_scores]\n",
    "ax2.bar(x=token_ids, height=e_scores, color=colors)\n",
    "ax2.set_ylabel(\"End Scores\")\n",
    "plt.xticks(token_ids, tokens, rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe75ee-00aa-49ee-90fe-880545875955",
   "metadata": {},
   "source": [
    "Putting the components together, we can now get the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fe4fc-8574-492e-ac18-0f2a2b9e9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619b472-3741-4af9-84c2-55c0921ff92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
